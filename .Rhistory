plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red" , lwd=2)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
line(dis, p, col="red" , lwd=2)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
line(dis, p)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines.default(dis, p)
plot(p)
plot(dis,p)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
plot(dis, p, col="red", lwd=2, add=TRUE)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
plot(dis, p, col="red", lwd=2, add=TRUE)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1, add=TRUE)
plot(dis, p, col="red", lwd=2)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2)
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'x')
?lines
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'p')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'b')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'p')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'o')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'p')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'l')
# Plot resulting data and polynomial fits
p <- predict(fit)
plot(dis, nox, pch=19, lwd=0.1)
lines(dis, p, col="red", lwd=2, type = 'p')
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p', lwd=2)
}
print(paste("degree = ", i, "r.squared = ", summary(fit)$r.squared))
}
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
print(paste("degree = ", i, "r.squared = ", summary(fit)$r.squared))
}
# Plot the resulting fit
p <- predict(fit)
plot(dis, nox, col="blue", lwd=2)
lines(dis, p, col="red" , lwd=2, type = 'p')
# Plot the resulting fit
p <- predict(fit)
plot(dis, nox, lwd=2)
lines(dis, p, col="red" , lwd=2, type = 'p')
# We can use the cv.glm() function to perform cross-validation
library(boot)
cv.err <- rep(0,10)
for (i in 1:10) {
fit <- glm(nox~poly(dis,degree = i))
cv.err[i] <- cv.glm(Boston, fit, K=10)$delta[1]
}
plot(cv.err, type="b",xlab="Degree", ylab="CV error")
# We can use the cv.glm() function to perform cross-validation
library(boot)
cv.err <- rep(0,10)
for (i in 1:10) {
fit <- glm(nox~poly(dis,degree = i))
cv.err[i] <- cv.glm(Boston, fit, K=10)$delta[1]
}
plot(cv.err, type="b",xlab="Degree", ylab="CV error")
# We can use the cv.glm() function to perform cross-validation
library(boot)
cv.err <- rep(0,10)
for (i in 1:10) {
fit <- glm(nox~poly(dis,degree = i))
cv.err[i] <- cv.glm(Boston, fit, K=10)$delta[1]
print(paste("degree = ", i, "cv.err = ", cv.err[i]))
}
plot(cv.err, type="b",xlab="Degree", ylab="CV error")
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
print(paste("degree = ", i, "r.squared = ", summary(fit)$r.squared))
}
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
print(paste("degree = ", i, "r.squared = ", summary(fit)$r.squared))
}
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
#add legend off plotted lines
legend("topright", legend = c("degree 3", "degree 6", "degree 9"), col = c(3,6,9), lty = 1, cex = 0.8))
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
#add legend off plotted lines
legend("topright", legend = c("degree 3", "degree 6", "degree 9"), col = c(3,6,9), lty = 1, cex = 0.8))
plot(dis,nox)
for (i in 1:10) {
fit <- lm(nox~poly(dis,degree = i))
p <- predict(fit)
if (i%%3==0){
lines(dis, p, col=i, lwd=2, type = 'p')
}
#add legend off plotted lines
legend("topright", legend = c("degree 3", "degree 6", "degree 9"), col = c(3,6,9), lty = 1, cex = 0.8)
print(paste("degree = ", i, "r.squared = ", summary(fit)$r.squared))
}
# We can use the cv.glm() function to perform cross-validation
library(boot)
cv.err <- rep(0,10)
for (i in 1:10) {
fit <- glm(nox~poly(dis,degree = i))
cv.err[i] <- cv.glm(Boston, fit, K=10)$delta[1]
print(paste("degree = ", i, "cv.err = ", cv.err[i]))
}
plot(cv.err, type="b",xlab="Degree", ylab="CV error")
cv.err <- rep(0,10)
for (i in 1:10) {
fit <- glm(nox~bs(dis,df = i))
rss <- sum(fit$residuals^2)
print(paste("degree = ", i, "RSS = ", rss))
cv.err[i] <- cv.glm(Boston, fit, K=10)$delta[1]
}
cv.err
print(cv.err)
# Fit a linear model including a b-spline using the function bs on times and select a suitable degree and the knots position. Compare this model with the previous ones and comment.
linear4 <- gam(accel ~ bs(times,knots = c(15,20,30,40)), data = mcycle)
library(mgcv)
library(splines)
# Fit a GAM
k_values <- 30:40
gcv_scores <- numeric(length(k_values))
for (i in seq_along(k_values)) {
gam_model <- gam(accel ~ s(times, k = k_values[i]), data = mcycle)
gcv_scores[i] <- gam_model$gcv.ubre
}
library(MASS)
plot(mcycle$accel ~ mcycle$times, xlab = "Time", ylab = "Acceleration", main = "")
library(mgcv)
gam_model_test <- gam(accel ~ s(times), data = mcycle)
# Fit a linear model including a b-spline using the function bs on times and select a suitable degree and the knots position. Compare this model with the previous ones and comment.
linear4 <- gam(accel ~ bs(times,knots = c(15,20,30,40)), data = mcycle)
plot(mcycle$times,mcycle$accel, xlab = "Time", ylab = "Acceleration", main = "Data with fitted linear model")
lines(mcycle$times, predict(linear4), col = "red")
summary(linear4)
shiny::runApp('Modelli/statistical_methods/FirstApp')
install.packages("haven")
data <- read_dta("Modelli/statistical_methods/exam/zambia_height92.dta")
library(haven)
data <- read_dta("Modelli/statistical_methods/exam/zambia_height92.dta")
head(data)
gc()
library(haven)
data <- read_dta("Modelli/statistical_methods/exam/zambia_height92.dta")
head(data)
str(data)
# import ggplot2
library(ggplot2)
View(data)
library(haven)
data <- read_dta("data/zambia_height92.dta")
head(data)
#split data in train and test set
set.seed(123)
train <- sample(1:nrow(data), 0.85*nrow(data))
test <- setdiff(1:nrow(data), train)
train_data <- data[train,]
test_data <- data[test,]
sum(is.na(train_data))
#check if all zscore values are integers
sum(train_data$zscore - as.integer(train_data$zscore))
#cast of zscore to integer
train_data$zscore <- as.integer(train_data$zscore)
#factorize gender
train_data$c_gender <- as.factor(train_data$c_gender)
#cast c_breastf as integer
train_data$c_breastf <- as.integer(train_data$c_breastf)
#cast c_age as integer
train_data$c_age <- as.integer(train_data$c_age)
#NOTE: to have the month of birth in m_agebirth calculate: decimal_part * 12
#factorize m_education
train_data$m_education <- as.factor(train_data$m_education)
#factorize m_work
train_data$m_work <- as.factor(train_data$m_work)
#factorize region
train_data$region <- as.factor(train_data$region)
#factorize district
train_data$district <- as.factor(train_data$district)
hist(train_data$zscore, breaks = 20, col = "lightblue", main = "Histogram of zscore", xlab = "zscore", freq = FALSE)
#add the normal curve with mean and sd of zscore
curve(dnorm(x, mean = mean(train_data$zscore), sd = sd(train_data$zscore)), col = "red", lwd = 2, add = TRUE)
#add the vertical dotted line at the mean, add it to the legend
abline(v = mean(train_data$zscore), col = "blue", lwd = 2, lty = 2)
legend("topright", c("Normal curve", "Mean"), col = c("red", "blue"), lwd = c(2, 2), lty = c(1, 2), cex = 1.5)
# Write the median and mean values to check if they're similar
text(350, 0.001, paste("Median:", round(median(train_data$zscore), 2), "\nMean:", round(mean(train_data$zscore), 2)), cex = 1.5)
#barplot of c_gender
table(train_data$c_gender)
#plot the previous distribution (zscore) for c_gender=0 and c_gender=1
hist(train_data$zscore[train_data$c_gender==0], breaks = 20, col = rgb(0,0,1,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE)
hist(train_data$zscore[train_data$c_gender==1], breaks = 20, col = rgb(1,0,0,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE, add = TRUE)
# add the mean line for both distributions
abline(v = mean(train_data$zscore[train_data$c_gender==0]), col = "blue", lwd = 2, lty = 2)
abline(v = mean(train_data$zscore[train_data$c_gender==1]), col = "red", lwd = 2, lty = 2)
#plot the distribution of the c_breastf variable
hist(train_data$c_breastf, breaks = 20, col = "lightblue", main = "Histogram of c_breastf", xlab = "c_breastf", freq = T)
library(ggplot2)
library(ggExtra)
install.packages("ggExtra")
library(ggplot2)
library(ggExtra)
#marginal plot of zscore and c_breastf
p <- ggplot(train_data, aes(x=c_breastf, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p1 <- ggMarginal(p, type="histogram")
p1
library(dplyr)
#plot the marginal distribution of the zscore variable for c_breastf > 2
p <- train_data %>%
filter(c_breastf > 2) %>%
ggplot(., aes(x=c_breastf, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p2 <- ggMarginal(p, type="histogram")
p2
cor.test(train_data$zscore[train_data$c_breastf > 2], train_data$c_breastf[train_data$c_breastf > 2])
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 20, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = T)
library(ggplot2)
library(ggExtra)
#marginal plot of zscore and c_breastf
p <- ggplot(train_data, aes(x=c_breastf, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p1 <- ggMarginal(p, type="histogram")
p1
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p3 <- ggMarginal(p, type="histogram")
p
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p3 <- ggMarginal(p, type="histogram")
p3
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 29, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = T)
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 28, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = T)
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 20, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = T)
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p3 <- ggMarginal(p, type="histogram",break=20)
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p3 <- ggMarginal(p, type="histogram",breaks =20)
p3
#marginal plot of zscore and c_age
p<- ggplot(train_data, aes(x=c_age, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p3 <- ggMarginal(p, type="histogram")
p3
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 29, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = T)
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 25, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = F)
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 20, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = F)
#plot the distribution of c_age variable
hist(train_data$c_age, breaks = 20, col = "lightblue", main = "Histogram of c_age", xlab = "c_age", freq = F)
#add a density curve
lines(density(train_data$c_age), col = "red", lwd = 2)
cor.test(train_data$zscore, train_data$c_age)
cor.test(train_data$c_breastf, train_data$c_age)
library(corrplot)
#correlation matrix for continuous variables
cor_matrix <- cor(train_data[,c("zscore", "c_breastf", "c_age", "m_agebirth","m_heght","m_bmi")])
library(corrplot)
#correlation matrix for continuous variables
cor_matrix <- cor(train_data[,c("zscore", "c_breastf", "c_age", "m_agebirth","m_heght","m_bmi")])
library(corrplot)
#correlation matrix for continuous variables
cor_matrix <- cor(train_data[,c("zscore", "c_breastf", "c_age", "m_agebirth", "m_height", "m_bmi")])
corrplot(cor_matrix, method = "circle", type = "upper", tl.col = "black", tl.srt = 45)
cor.test(train_data$zscore, train_data$c_age)
install.packages("R2BayesX")
cor.test(train_data$c_breastf, train_data$c_age)
#plot the distribution of m_agebirth variable
hist(train_data$m_agebirth, breaks = 20, col = "lightblue", main = "Histogram of m_agebirth", xlab = "m_agebirth", freq = F)
#add a density curve
lines(density(train_data$m_agebirth), col = "red", lwd = 2)
#plot the distribution of m_agebirth variable
hist(train_data$m_agebirth, breaks = 20, col = "lightblue", main = "Histogram of m_agebirth", xlab = "m_agebirth", freq = F)
#add a density curve
lines(density(train_data$m_agebirth), col = "red", lwd = 2)
#add the mean line and the median line
abline(v = mean(train_data$m_agebirth), col = "blue", lwd = 2, lty = 2)
abline(v = median(train_data$m_agebirth), col = "green", lwd = 2, lty = 4)
#plot the distribution of m_height variable
hist(train_data$m_height, breaks = 20, col = "lightblue", main = "Histogram of m_height", xlab = "m_height", freq = F)
#add a density curve
lines(density(train_data$m_height), col = "red", lwd = 2)
#plot the distribution of m_height variable
hist(train_data$m_height, breaks = 20, col = "lightblue", main = "Histogram of m_height", xlab = "m_height", freq = F)
#add a normal distribution curve with the same mean and sd as the variable
curve(dnorm(x, mean = mean(train_data$m_height), sd = sd(train_data$m_height)), col = "red", lwd = 2, add = TRUE)
#add the mean line
abline(v = mean(train_data$m_height), col = "blue", lwd = 2, lty = 2)
#marginal plot of zscore and m_height
p<- ggplot(train_data, aes(x=m_height, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p4 <- ggMarginal(p, type="histogram")
p4
#plot the distribution of m_bmi variable
hist(train_data$m_bmi, breaks = 20, col = "lightblue", main = "Histogram of m_bmi", xlab = "m_bmi", freq = F)
#add a normal distribution curve with the same mean and sd as the variable
curve(dnorm(x, mean = mean(train_data$m_bmi), sd = sd(train_data$m_bmi)), col = "red", lwd = 2, add = TRUE)
#add the mean line
abline(v = mean(train_data$m_bmi), col = "blue", lwd = 2, lty = 2)
#plot the distribution of m_bmi variable
hist(train_data$m_bmi, breaks = 20, col = "lightblue", main = "Histogram of m_bmi", xlab = "m_bmi", freq = F)
#add a the density line
lines(density(train_data$m_bmi), col = "red", lwd = 2)
#add the mean line and median line
abline(v = mean(train_data$m_bmi), col = "blue", lwd = 2, lty = 2)
abline(v = median(train_data$m_bmi), col = "green", lwd = 2, lty = 4)
#marginal plot of zscore and m_bmi
p<- ggplot(train_data, aes(x=m_bmi, y=zscore)) +
geom_point() +
theme(legend.position="none") +
# add a regression line
geom_smooth(method=lm, se=FALSE)
p5 <- ggMarginal(p, type="histogram")
p5
#plot the previous distribution (zscore) for c_gender=0 and c_gender=1
hist(train_data$zscore[train_data$c_gender==0], breaks = 20, col = rgb(0,0,1,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE)
hist(train_data$zscore[train_data$c_gender==1], breaks = 20, col = rgb(1,0,0,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE, add = TRUE)
# add the mean line for both distributions
abline(v = mean(train_data$zscore[train_data$c_gender==0]), col = "blue", lwd = 2, lty = 2)
abline(v = mean(train_data$zscore[train_data$c_gender==1]), col = "red", lwd = 2, lty = 2)
#plot the previous distribution (zscore) for m_work=0 and m_workr=1
hist(train_data$zscore[train_data$m_work==0], breaks = 20, col = rgb(0,0,1,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE)
hist(train_data$zscore[train_data$m_work==1], breaks = 20, col = rgb(1,0,0,1/4), main = "Histogram of zscore", xlab = "zscore", freq = FALSE, add = TRUE)
#table of the number of observations for each value of m_work
table(train_data$m_work)
max(train_data$m_education)
unique(train_data$m_education)
par(mfrow=c(1,4))
#hist of zscore for each value of m_education
for (i in 0:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), main = paste("Histogram of zscore for m_education =", i), xlab = "zscore", freq = FALSE)
}
par(mfrow=c(1,4))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), main = paste("Histogram of zscore for m_education =", i), xlab = "zscore", freq = FALSE)
}
par(mfrow=c(4,1))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), main = paste("Histogram of zscore for m_education =", i), xlab = "zscore", freq = FALSE)
}
par(mfrow=c(4,1))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), main = paste("Histogram of zscore for m_education =", i), xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), main = paste("Histogram of zscore for m_education =", i), xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
par(mfrow=c(4,1))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
par(mfrow=c(2,2))
#hist of zscore for each value of m_education
for (i in 1:4){
hist(train_data$zscore[train_data$m_education==i], breaks = 20, col = rgb(0,0,1,1/4), , xlab = "zscore", freq = FALSE)
}
shiny::runApp('Modelli/statistical_methods/exam/exam')
sum(is.null(train_data))
sum(is.na(train_data))
table(is.na(train_data))
setwd("~/Modelli/statistical_methods/SM2324_GroupK")
library(shiny); runApp('full_app.R')
